{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "from constants import *\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "pd.options.display.max_rows = 2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.read_pickle(join(ETL_PATH, 'dewiki_phrases_joined.pickle'))\n",
    "ps = set(p)\n",
    "\n",
    "bad = {\n",
    "    'ab', 'seit', 'in', 'der', 'die', 'das', 'an', 'am', 'diese', 'bis', 'ein'\n",
    "}\n",
    "\n",
    "\n",
    "def ngrams(ser):\n",
    "    if ser[0].lower() not in bad:\n",
    "        s = ser.str.cat(sep='_')\n",
    "        size = len(ser)\n",
    "        while size > 1:\n",
    "            if s in ps:\n",
    "                return s, size\n",
    "            s = s.rsplit('_', 1)[0]\n",
    "            size -= 1\n",
    "    return np.nan, 0\n",
    "\n",
    "\n",
    "pattern = re.compile(r'F')\n",
    "files = sorted([f for f in listdir(SMPL_PATH)\n",
    "                if (isfile(join(SMPL_PATH, f)) and pattern.match(f))])\n",
    "\n",
    "for name in files[:]:\n",
    "    gc.collect()\n",
    "    corpus = name.split('.')[0]\n",
    "    print(corpus)\n",
    "    \n",
    "    f = join(SMPL_PATH, corpus + '.pickle')\n",
    "    df = pd.read_pickle(f)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df['__2'] = df.token.shift(-1)\n",
    "    df['__3'] = df.token.shift(-2)\n",
    "    df['__4'] = df.token.shift(-3)\n",
    "    df['__5'] = df.token.shift(-4)\n",
    "    d = df[[TOKEN, '__2', '__3', '__4', '__5']].progress_apply(ngrams, axis=1)\n",
    "    d = pd.DataFrame.from_records(d.tolist(), columns=['phrase', 'length'])\n",
    "    mask = ~d.phrase.isnull()\n",
    "    df = pd.concat([df, d], axis=1).drop(['__2', '__3', '__4', '__5'], axis=1)\n",
    "    df.loc[mask, TOKEN] = df.loc[mask, 'phrase']\n",
    "    df.loc[mask, POS] = 'NPHRASE'\n",
    "    lv = df.length.values\n",
    "    keep = np.ones_like(lv, dtype=bool)\n",
    "    length = len(keep)\n",
    "    for i, v in enumerate(lv):\n",
    "        if v > 0:\n",
    "            for j in range(i + 1, min(i + v, length)):\n",
    "                if lv[j] == 0:\n",
    "                    keep[j] = False\n",
    "    df['keep'] = keep\n",
    "    df = df[df.keep].drop(['phrase', 'length', 'keep'], axis=1)\n",
    "    f = join(SMPL_PATH, corpus + '_wiki_phrases.pickle')\n",
    "    df.to_pickle(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
