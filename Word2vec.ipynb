{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join, exists\n",
    "import gc\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import logging\n",
    "from constants import *\n",
    "from itertools import islice\n",
    "\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument(\"retrain\")  # Number of training epochs\n",
    "#parser.add_argument(\"cores\")  # Number of training epochs\n",
    "#parser.add_argument(\"epochs\")  # Number of training epochs\n",
    "#parser.add_argument(\"input_dir\")\n",
    "#parser.add_argument(\"output_dir\")\n",
    "#parser.add_argument(\"model_dir\")\n",
    "#args = parser.parse_args()\n",
    "\n",
    "retrain = False\n",
    "cores = 7\n",
    "epochs = 5\n",
    "\n",
    "print('cpu count:', multiprocessing.cpu_count())\n",
    "print('worker count:', cores)\n",
    "\n",
    "input_dir = join(SMPL_PATH, 'dewiki/cache')\n",
    "out_dir = join(ETL_PATH, 'NETL/trained_models/w2v_lemma')\n",
    "\n",
    "if not exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "model_file = join(out_dir, 'w2v_lemma')\n",
    "\n",
    "\n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "    \"\"\"Callback to log information about training\"\"\"\n",
    "    def __init__(self):\n",
    "        self.epoch = 1\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(\"Epoch #{} start\".format(self.epoch))\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(\"Epoch #{} end\".format(self.epoch))\n",
    "        self.epoch += 1\n",
    "\n",
    "\n",
    "class EpochSaver(CallbackAny2Vec):\n",
    "    \"\"\"Callback to save model after each epoch.\"\"\"\n",
    "    def __init__(self, path_prefix):\n",
    "        self.path_prefix = path_prefix\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        output_path = '{}_epoch{}.model'.format(self.path_prefix, self.epoch)\n",
    "        model.save(output_path)\n",
    "        self.epoch += 1\n",
    "\n",
    "files = sorted([f for f in listdir(input_dir)\n",
    "                if isfile(join(input_dir, f))])\n",
    "\n",
    "class Sentences(object):\n",
    "    def __iter__(self):\n",
    "        for name in files[:]:\n",
    "            gc.collect()\n",
    "            corpus = name.split('.')[0]\n",
    "            f = join(input_dir, name)\n",
    "            ser = pd.read_pickle(f)\n",
    "            for sent in ser:\n",
    "                # the conversion of the hash_id to str is necessary since gensim trys to allocate \n",
    "                # an array for ids of size 2^64 if int values are too big.\n",
    "                yield sent\n",
    "\n",
    "sentences = Sentences()\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "epoch_saver = EpochSaver(out_file)\n",
    "epoch_logger = EpochLogger()\n",
    "\n",
    "# Model initialization\n",
    "if retrain == 'True':\n",
    "    print('load existing model from', model_file)\n",
    "    model = Word2Vec.load(model_file)\n",
    "    out_file = model_file + 'retrained{:d}epochs'.format(epochs)\n",
    "else:\n",
    "    print('construct new model')\n",
    "    model = Word2Vec(\n",
    "        size=300,\n",
    "        window=5,\n",
    "        min_count=20,\n",
    "        workers=cores,\n",
    "        sample=0.00001,\n",
    "        negative=5,\n",
    "        sg=1,\n",
    "        #callbacks=[epoch_logger, epoch_saver],\n",
    "        iter=epochs,\n",
    "    )\n",
    "    model.build_vocab(sentences)\n",
    "    out_file = model_file\n",
    "\n",
    "# Model Training\n",
    "print('retrain {:d} epochs'.format(epochs))\n",
    "model.train(\n",
    "    sentences,\n",
    "    total_examples=model.corpus_count,\n",
    "    epochs=epochs,\n",
    "    report_delay=60.0,\n",
    "    callbacks=[epoch_logger, epoch_saver],\n",
    ")\n",
    "\n",
    "print('write model to', out_file)\n",
    "model.save(out_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
