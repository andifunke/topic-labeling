{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir, makedirs\n",
    "from os.path import isfile, isdir, join\n",
    "from constants import DATA_BASE, ETL_PATH, NLP_PATH, SMPL_PATH, HASH\n",
    "import pandas as pd\n",
    "import gc\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "pd.options.display.max_rows = 2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore = ['good', 'categories', 'hashmap', 'links', 'meta', 'phrases', 'sample', 'cache']\n",
    "re_ignore = r'.*?(' + '|'.join(ignore) + r').*?'\n",
    "ignore_pattern = re.compile(re_ignore)\n",
    "\n",
    "datasets = ['Europarl', 'FAZ_combined', 'FOCUS_cleansed', 'OnlineParticipation', 'PoliticalSpeeches', 'dewiki', 'dewac']\n",
    "re_include = r'^(' + '|'.join(datasets) + r').*'\n",
    "include_pattern = re.compile(re_include)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics for the ETL pipeline\n",
    "stats = []\n",
    "path = ETL_PATH\n",
    "files = sorted([f for f in listdir(path)\n",
    "                    if (\n",
    "                        isfile(join(path, f))\n",
    "                        and include_pattern.match(f)\n",
    "                        and not ignore_pattern.search(f)\n",
    "                       )\n",
    "               ], key=lambda x: x.lower())\n",
    "\n",
    "for name in files:\n",
    "    gc.collect()\n",
    "    full_path = join(path, name)\n",
    "    if not isfile(full_path):\n",
    "        continue\n",
    "\n",
    "    print('reading', name)\n",
    "    corpus = re.split(r'_.', name)[0]\n",
    "    df = pd.read_pickle(join(path, name))\n",
    "    stats.append((corpus, path, len(df), None, None, int(df.index[0]), df.title.iloc[0]))\n",
    "    \n",
    "with open(join(ETL_PATH, 'stats_etl.json'), 'w') as fp:\n",
    "    json.dump(stats, fp, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# statistics for the NLP pipeline\n",
    "stats = []\n",
    "path = NLP_PATH\n",
    "files = sorted([f for f in listdir(path)\n",
    "                    if (\n",
    "                        isfile(join(path, f))\n",
    "                        and include_pattern.match(f)\n",
    "                        and not ignore_pattern.search(f)\n",
    "                       )\n",
    "               ], key=lambda x: x.lower())\n",
    "\n",
    "for name in files:\n",
    "    gc.collect()\n",
    "    full_path = join(path, name)\n",
    "    if not isfile(full_path):\n",
    "        continue\n",
    "\n",
    "    print('reading', name)\n",
    "    corpus = re.split(r'_.', name)[0]\n",
    "    df = pd.read_pickle(join(path, name))\n",
    "    stats.append((corpus, path, len(np.unique(df.hash.values)), len(np.unique(df.sent_idx.values)), len(df), int(df.hash.iloc[0]), df.token.iloc[0]))\n",
    "    gc.collect()\n",
    "    \n",
    "with open(join(ETL_PATH, 'stats_nlp.json'), 'w') as fp:\n",
    "    json.dump(stats, fp, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# statistics for the phrase extraction pipeline\n",
    "stats = []\n",
    "path = SMPL_PATH\n",
    "files = [f for f in listdir(path) \n",
    "         if include_pattern.match(f) and not ignore_pattern.search(f)\n",
    "        ]\n",
    "\n",
    "# include dewiki subdir\n",
    "for name in files:\n",
    "    full_path = join(path, name)\n",
    "    if isdir(full_path):\n",
    "        subdir = [join(name, f) for f in listdir(full_path)\n",
    "                 if include_pattern.match(f) and not ignore_pattern.search(f)]\n",
    "        files += subdir\n",
    "        \n",
    "for name in sorted(files, key=lambda x: x.lower()):\n",
    "    gc.collect()\n",
    "    full_path = join(path, name)\n",
    "    if not isfile(full_path):\n",
    "        continue\n",
    "\n",
    "    print('reading', name)\n",
    "    df = pd.read_pickle(full_path)\n",
    "    corpus = re.split(r'_.', name)[0]\n",
    "    doc_stats = (corpus, path, len(np.unique(df.hash.values)), len(np.unique(df.sent_idx.values)), len(df), int(df.hash.iloc[0]), df.token.iloc[0])\n",
    "    print(doc_stats)\n",
    "    stats.append(doc_stats)\n",
    "    gc.collect()\n",
    "    \n",
    "with open(join(ETL_PATH, 'stats_smpl.json'), 'w') as fp:\n",
    "    json.dump(stats, fp, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# statistics for the phrase extraction pipeline pt2. (including Wikipedia phrases)\n",
    "stats = []\n",
    "path = join(SMPL_PATH, 'wiki_phrases')\n",
    "files = listdir(path)\n",
    "\n",
    "for name in sorted(files, key=lambda x: x.lower()):\n",
    "    gc.collect()\n",
    "    full_path = join(path, name)\n",
    "    if not isfile(full_path):\n",
    "        continue\n",
    "\n",
    "    print('reading', name)\n",
    "    df = pd.read_pickle(full_path)\n",
    "    corpus = re.split(r'_.', name)[0]\n",
    "    doc_stats = (corpus, path, len(np.unique(df.hash.values)), len(np.unique(df.sent_idx.values)), len(df), int(df.hash.iloc[0]), df.token.iloc[0])\n",
    "    print(doc_stats)\n",
    "    stats.append(doc_stats)\n",
    "    gc.collect()\n",
    "    \n",
    "with open(join(ETL_PATH, 'stats_wiki_phrases.json'), 'w') as fp:\n",
    "    json.dump(stats, fp, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>nb_docs</th>\n",
       "      <th>nb_sents</th>\n",
       "      <th>nb_words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corpus</th>\n",
       "      <th>path</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Europarl</th>\n",
       "      <th>../data/preprocessed</th>\n",
       "      <td>12788</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/preprocessed/nlp</th>\n",
       "      <td>12788</td>\n",
       "      <td>2575653</td>\n",
       "      <td>56247967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/preprocessed/simple</th>\n",
       "      <td>12788</td>\n",
       "      <td>2575653</td>\n",
       "      <td>54883666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/preprocessed/simple/wiki_phrases</th>\n",
       "      <td>12788</td>\n",
       "      <td>2571547</td>\n",
       "      <td>54747950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">FAZ</th>\n",
       "      <th>../data/preprocessed</th>\n",
       "      <td>49758</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/preprocessed/nlp</th>\n",
       "      <td>49758</td>\n",
       "      <td>1552118</td>\n",
       "      <td>27029604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/preprocessed/simple</th>\n",
       "      <td>49758</td>\n",
       "      <td>1552118</td>\n",
       "      <td>26386078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/preprocessed/simple/wiki_phrases</th>\n",
       "      <td>49758</td>\n",
       "      <td>1551960</td>\n",
       "      <td>26248649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">FOCUS</th>\n",
       "      <th>../data/preprocessed</th>\n",
       "      <td>86158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/preprocessed/nlp</th>\n",
       "      <td>86158</td>\n",
       "      <td>1667720</td>\n",
       "      <td>25488267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/preprocessed/simple</th>\n",
       "      <td>86158</td>\n",
       "      <td>1667720</td>\n",
       "      <td>24652775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/preprocessed/simple/wiki_phrases</th>\n",
       "      <td>86158</td>\n",
       "      <td>1666915</td>\n",
       "      <td>24469096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">OnlineParticipation</th>\n",
       "      <th>../data/preprocessed</th>\n",
       "      <td>26138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/preprocessed/nlp</th>\n",
       "      <td>25981</td>\n",
       "      <td>137525</td>\n",
       "      <td>1725466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/preprocessed/simple</th>\n",
       "      <td>25981</td>\n",
       "      <td>137522</td>\n",
       "      <td>1663376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/preprocessed/simple/wiki_phrases</th>\n",
       "      <td>25981</td>\n",
       "      <td>137499</td>\n",
       "      <td>1661338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">PoliticalSpeeches</th>\n",
       "      <th>../data/preprocessed</th>\n",
       "      <td>6038</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/preprocessed/nlp</th>\n",
       "      <td>6037</td>\n",
       "      <td>619510</td>\n",
       "      <td>11611442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/preprocessed/simple</th>\n",
       "      <td>6037</td>\n",
       "      <td>619510</td>\n",
       "      <td>11336693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/preprocessed/simple/wiki_phrases</th>\n",
       "      <td>6037</td>\n",
       "      <td>619452</td>\n",
       "      <td>11297096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dewac</th>\n",
       "      <th>../data/preprocessed</th>\n",
       "      <td>1751871</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/preprocessed/nlp</th>\n",
       "      <td>1751871</td>\n",
       "      <td>113995124</td>\n",
       "      <td>1644236130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/preprocessed/simple</th>\n",
       "      <td>1747499</td>\n",
       "      <td>111748206</td>\n",
       "      <td>1620832054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/preprocessed/simple/wiki_phrases</th>\n",
       "      <td>1747499</td>\n",
       "      <td>111727355</td>\n",
       "      <td>1615160567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dewiki</th>\n",
       "      <th>../data/preprocessed</th>\n",
       "      <td>2215487</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/preprocessed/nlp</th>\n",
       "      <td>1973512</td>\n",
       "      <td>48192772</td>\n",
       "      <td>836453636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>../data/preprocessed/simple</th>\n",
       "      <td>1970432</td>\n",
       "      <td>48039951</td>\n",
       "      <td>785357226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              nb_docs  \\\n",
       "corpus              path                                                \n",
       "Europarl            ../data/preprocessed                        12788   \n",
       "                    ../data/preprocessed/nlp                    12788   \n",
       "                    ../data/preprocessed/simple                 12788   \n",
       "                    ../data/preprocessed/simple/wiki_phrases    12788   \n",
       "FAZ                 ../data/preprocessed                        49758   \n",
       "                    ../data/preprocessed/nlp                    49758   \n",
       "                    ../data/preprocessed/simple                 49758   \n",
       "                    ../data/preprocessed/simple/wiki_phrases    49758   \n",
       "FOCUS               ../data/preprocessed                        86158   \n",
       "                    ../data/preprocessed/nlp                    86158   \n",
       "                    ../data/preprocessed/simple                 86158   \n",
       "                    ../data/preprocessed/simple/wiki_phrases    86158   \n",
       "OnlineParticipation ../data/preprocessed                        26138   \n",
       "                    ../data/preprocessed/nlp                    25981   \n",
       "                    ../data/preprocessed/simple                 25981   \n",
       "                    ../data/preprocessed/simple/wiki_phrases    25981   \n",
       "PoliticalSpeeches   ../data/preprocessed                         6038   \n",
       "                    ../data/preprocessed/nlp                     6037   \n",
       "                    ../data/preprocessed/simple                  6037   \n",
       "                    ../data/preprocessed/simple/wiki_phrases     6037   \n",
       "dewac               ../data/preprocessed                      1751871   \n",
       "                    ../data/preprocessed/nlp                  1751871   \n",
       "                    ../data/preprocessed/simple               1747499   \n",
       "                    ../data/preprocessed/simple/wiki_phrases  1747499   \n",
       "dewiki              ../data/preprocessed                      2215487   \n",
       "                    ../data/preprocessed/nlp                  1973512   \n",
       "                    ../data/preprocessed/simple               1970432   \n",
       "\n",
       "                                                               nb_sents  \\\n",
       "corpus              path                                                  \n",
       "Europarl            ../data/preprocessed                              0   \n",
       "                    ../data/preprocessed/nlp                    2575653   \n",
       "                    ../data/preprocessed/simple                 2575653   \n",
       "                    ../data/preprocessed/simple/wiki_phrases    2571547   \n",
       "FAZ                 ../data/preprocessed                              0   \n",
       "                    ../data/preprocessed/nlp                    1552118   \n",
       "                    ../data/preprocessed/simple                 1552118   \n",
       "                    ../data/preprocessed/simple/wiki_phrases    1551960   \n",
       "FOCUS               ../data/preprocessed                              0   \n",
       "                    ../data/preprocessed/nlp                    1667720   \n",
       "                    ../data/preprocessed/simple                 1667720   \n",
       "                    ../data/preprocessed/simple/wiki_phrases    1666915   \n",
       "OnlineParticipation ../data/preprocessed                              0   \n",
       "                    ../data/preprocessed/nlp                     137525   \n",
       "                    ../data/preprocessed/simple                  137522   \n",
       "                    ../data/preprocessed/simple/wiki_phrases     137499   \n",
       "PoliticalSpeeches   ../data/preprocessed                              0   \n",
       "                    ../data/preprocessed/nlp                     619510   \n",
       "                    ../data/preprocessed/simple                  619510   \n",
       "                    ../data/preprocessed/simple/wiki_phrases     619452   \n",
       "dewac               ../data/preprocessed                              0   \n",
       "                    ../data/preprocessed/nlp                  113995124   \n",
       "                    ../data/preprocessed/simple               111748206   \n",
       "                    ../data/preprocessed/simple/wiki_phrases  111727355   \n",
       "dewiki              ../data/preprocessed                              0   \n",
       "                    ../data/preprocessed/nlp                   48192772   \n",
       "                    ../data/preprocessed/simple                48039951   \n",
       "\n",
       "                                                                nb_words  \n",
       "corpus              path                                                  \n",
       "Europarl            ../data/preprocessed                               0  \n",
       "                    ../data/preprocessed/nlp                    56247967  \n",
       "                    ../data/preprocessed/simple                 54883666  \n",
       "                    ../data/preprocessed/simple/wiki_phrases    54747950  \n",
       "FAZ                 ../data/preprocessed                               0  \n",
       "                    ../data/preprocessed/nlp                    27029604  \n",
       "                    ../data/preprocessed/simple                 26386078  \n",
       "                    ../data/preprocessed/simple/wiki_phrases    26248649  \n",
       "FOCUS               ../data/preprocessed                               0  \n",
       "                    ../data/preprocessed/nlp                    25488267  \n",
       "                    ../data/preprocessed/simple                 24652775  \n",
       "                    ../data/preprocessed/simple/wiki_phrases    24469096  \n",
       "OnlineParticipation ../data/preprocessed                               0  \n",
       "                    ../data/preprocessed/nlp                     1725466  \n",
       "                    ../data/preprocessed/simple                  1663376  \n",
       "                    ../data/preprocessed/simple/wiki_phrases     1661338  \n",
       "PoliticalSpeeches   ../data/preprocessed                               0  \n",
       "                    ../data/preprocessed/nlp                    11611442  \n",
       "                    ../data/preprocessed/simple                 11336693  \n",
       "                    ../data/preprocessed/simple/wiki_phrases    11297096  \n",
       "dewac               ../data/preprocessed                               0  \n",
       "                    ../data/preprocessed/nlp                  1644236130  \n",
       "                    ../data/preprocessed/simple               1620832054  \n",
       "                    ../data/preprocessed/simple/wiki_phrases  1615160567  \n",
       "dewiki              ../data/preprocessed                               0  \n",
       "                    ../data/preprocessed/nlp                   836453636  \n",
       "                    ../data/preprocessed/simple                785357226  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggregating statistics\n",
    "path = ETL_PATH\n",
    "files = sorted([f for f in listdir(path) if re.match(r'stats.*?json$', f)])\n",
    "stats = []\n",
    "for name in files:\n",
    "    full_path = join(path, name)\n",
    "    with open(join(ETL_PATH, name), 'r') as fp:\n",
    "        stats += json.load(fp)\n",
    "\n",
    "df = pd.DataFrame.from_records(stats, columns=['file', 'path', 'nb_docs', 'nb_sents', 'nb_words', 'doc_hash', 'first_token'])\n",
    "df['corpus'] = df.file.map(lambda x: re.split(r'[_./]', x)[0])\n",
    "dfx = df.groupby(['corpus', 'path']).sum().drop('doc_hash', axis=1)\n",
    "dfx[['nb_docs', 'nb_sents', 'nb_words']] = dfx[['nb_docs', 'nb_sents', 'nb_words']].astype('int64')\n",
    "dfx.to_csv(join(ETL_PATH, 'stats.csv'))\n",
    "dfx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
