{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from os.path import join\n",
    "import csv\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, '')\n",
    "\n",
    "from constants import DATA_BASE\n",
    "\n",
    "# Warning: The xml.etree.ElementTree module is not secure against maliciously constructed data. \n",
    "# If you need to parse untrusted or unauthenticated data see XML vulnerabilities \n",
    "# (https://docs.python.org/3/library/xml.html#xml-vulnerabilities)\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "#import re\n",
    "#from w3lib.html import remove_tags, remove_tags_with_content\n",
    "from html import unescape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_WIKI_XML = join(DATA_BASE, 'dewiki')\n",
    "FILENAME_WIKI = 'dewiki-latest-pages-articles.xml'\n",
    "FILENAME_ARTICLES = 'articles.csv'\n",
    "\n",
    "pathWikiXML = join(PATH_WIKI_XML, FILENAME_WIKI)\n",
    "pathArticles = join(PATH_WIKI_XML, FILENAME_ARTICLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "def strip_tag(tag):\n",
    "    return tag.split('}', 1)[1] if '}' in tag else tag\n",
    "\n",
    "def split_title(title):\n",
    "    split = title.find('(', 1)\n",
    "    split = None if split < 1 else split\n",
    "    return title[:split], (title[split:] if split else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml(infile, outfile, iterations, print_every=1000):\n",
    "\n",
    "    with open(infile, 'r') as fr, open(outfile, 'w') as fw:\n",
    "\n",
    "        fields = ['id', 'timestamp', 'title', 'subtitle', 'text', 'categories', 'links', 'redirect']\n",
    "        writer = csv.DictWriter(fw, fields, quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writeheader()\n",
    "\n",
    "        articleCount = 0\n",
    "        row = None\n",
    "        is_article = is_liste = is_redirect = False\n",
    "\n",
    "        for event, elem in ET.iterparse(fr, events=['start', 'end']):\n",
    "            tag = strip_tag(elem.tag)\n",
    "\n",
    "            if event == 'start':\n",
    "                # start new row\n",
    "                if tag == 'page':\n",
    "                    row = dict()\n",
    "            else:\n",
    "                if tag == 'title':\n",
    "                    if elem.text.startswith('Liste von'):\n",
    "                        is_liste = True\n",
    "                    else:\n",
    "                        row[tag], row['subtitle'] = split_title(elem.text)\n",
    "                        #print(row[tag], end=': ')\n",
    "                elif tag == 'ns' and int(elem.text) == 0:\n",
    "                    if is_liste:\n",
    "                        is_article = False\n",
    "                    else:\n",
    "                        is_article = True\n",
    "                elif tag == 'id' and tag not in row:\n",
    "                    row[tag] = elem.text\n",
    "                elif tag == 'timestamp':\n",
    "                    row[tag] = elem.text\n",
    "                elif tag == 'redirect':\n",
    "                    is_redirect = True\n",
    "                    row[tag] = elem.get('title')\n",
    "                elif tag == 'text' and is_article and not is_redirect:\n",
    "                    row[tag], row['categories'], row['links'] = parse_text(elem.text)\n",
    "                    if not row[tag]:\n",
    "                        is_article = False\n",
    "                # write and close row, reset flags\n",
    "                elif tag == 'page':\n",
    "                    if is_article:\n",
    "                        writer.writerow(row)\n",
    "                        articleCount += 1\n",
    "                        # print status\n",
    "                        if articleCount > 1 and (articleCount % print_every) == 0:\n",
    "                            print(locale.format(\"%d\", articleCount, grouping=True))\n",
    "                    # reset everything\n",
    "                    row = None\n",
    "                    #print(is_article, is_liste, is_redicret)\n",
    "                    is_article = is_liste = is_redirect = False\n",
    "                elem.clear()\n",
    "\n",
    "            if articleCount == iterations:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000\n",
      "2.000\n",
      "3.000\n",
      "4.000\n",
      "5.000\n",
      "6.000\n",
      "7.000\n",
      "8.000\n",
      "9.000\n",
      "10.000\n",
      "CPU times: user 23.1 s, sys: 248 ms, total: 23.3 s\n",
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# We will keep the header decorations to subdivide an article at a later stage\n",
    "\n",
    "# matches against: [[Kategorie:Soziologische Systemtheorie]], [[Kategorie:Fiktive Person|Smithee, Alan]]\n",
    "category = r\"\\[\\[Kategorie:(?P<cat>[\\w ]+)(?:\\|.*)?\\]\\]\"\n",
    "re_category = re.compile(category)\n",
    "\n",
    "# remove tags\n",
    "refs =     r\"<\\s*(ref|math)[^>.]*?(?:\\/\\s*>|>.*?<\\s*\\/\\s*(ref|math)\\s*>)\"\n",
    "tags =     r\"<(.|\\n)*?>\"\n",
    "re_tags = re.compile(r\"(%s|%s)\" % (refs, tags), re.MULTILINE)\n",
    "\n",
    "table =    r\"{\\|(?s:.*?)\\|}\"\n",
    "re_table = re.compile(table)\n",
    "\n",
    "# remove meta data: [[Datei:...]]\n",
    "chars =    r\"\\xa0\"\n",
    "emph =     r\"\\'{2,}\"\n",
    "bullet =   r\"^[\\*:] *\"\n",
    "bullet2 =  r\"^\\|.*\"\n",
    "meta =     r\"\\[\\[\\w+:.*?\\]\\]\"\n",
    "footer =   r\"== (Bibliographie|Literatur|Weblinks|Einzelnachweise) ==(?s:.)*\"\n",
    "re_meta = re.compile(r\"(%s|%s|%s|%s|%s|%s)\" % (chars, emph, bullet, bullet2, meta, footer), re.MULTILINE)\n",
    "\n",
    "# => merge ^\n",
    "remove = r'(' + r'|'.join([refs, tags, table, chars, emph, bullet, bullet2, meta, footer]) + r')'\n",
    "re_remove = re.compile(remove, re.MULTILINE)\n",
    "\n",
    "# matches against: [[Aristoteles]], [[Reductio ad absurdum|indirekten Beweis]]\n",
    "wikilink = r\"\\[\\[(.*?)\\]\\]\"\n",
    "re_link = re.compile(wikilink)\n",
    "\n",
    "zitat =    r\"{{Zitat(?:\\||-.*?\\|Übersetzung=)(?P<token>.*?)(?:\\|.*?)?}}\"\n",
    "re_zitat = re.compile(zitat)\n",
    "\n",
    "replace = r'(' + r'|'.join([wikilink, zitat]) + r')'\n",
    "re_replace = re.compile(replace)\n",
    "\n",
    "infobox =  r\"{{.*?(?:}}|(?={{))\"\n",
    "re_infobox = re.compile(r\"(%s)\" % (infobox), re.DOTALL)\n",
    "\n",
    "lf      = r\"\\n\\n*\\n(?!==)\"\n",
    "re_lf = re.compile(lf)\n",
    "\n",
    "\n",
    "def parse_text(text):\n",
    "    # replace html escapings\n",
    "    text = unescape(text)\n",
    "\n",
    "    # extract categories\n",
    "    categories = re_category.findall(text)\n",
    "\n",
    "    #text = re_remove.sub('', text)\n",
    "\n",
    "    # remove formatting tags and ref/math tags with content\n",
    "    text = re_tags.sub('', text)\n",
    "\n",
    "    # remove tables\n",
    "    text = re_table.sub('', text)\n",
    "\n",
    "    # remove metadata and formatting\n",
    "    text = re_meta.sub('', text)\n",
    "\n",
    "    # replace citations\n",
    "    text = re_zitat.sub(r\"„\\g<token>”\", text)\n",
    "\n",
    "    # replace WikiLinks\n",
    "    links = []\n",
    "    def replace_links(matchobj):\n",
    "        #if 'token' in matchobj.groupdict():\n",
    "        #    return \"„\" + matchobj.group('token') + \"”\"\n",
    "        split = matchobj.group(1).split('|', 1) \n",
    "        links.append(split[0])\n",
    "        return split[1] if len(split) > 1 else split[0]\n",
    "    text = re_link.sub(replace_links, text)\n",
    "    #text = re_replace.sub(replace_links, text)\n",
    "    \n",
    "    # repeat for nested structures, performancewise not perfect\n",
    "    n = 1\n",
    "    while n > 0:\n",
    "        text, n = re_infobox.subn('', text)\n",
    "    \n",
    "    text = re_lf.sub('\\n', text)\n",
    "    return text.strip(' \\n}{'), categories, links\n",
    "\n",
    "%time parse_xml(pathWikiXML, pathArticles+'re2', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jt -r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
