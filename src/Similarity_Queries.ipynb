{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-28 20:08:03,753 : INFO : loading Dictionary object from dewac_noun_tfidf.dict\n",
      "2018-11-28 20:08:03,792 : INFO : loaded dewac_noun_tfidf.dict\n",
      "2018-11-28 20:08:03,968 : INFO : loaded corpus index from dewac_noun_tfidf.mm.index\n",
      "2018-11-28 20:08:03,968 : INFO : initializing cython corpus reader from dewac_noun_tfidf.mm\n",
      "2018-11-28 20:08:03,969 : INFO : accepted corpus with 1747499 documents, 100000 features, 188870159 non-zero entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MmCorpus(1747499 documents, 100000 features, 188870159 non-zero entries)\n"
     ]
    }
   ],
   "source": [
    "from os.path import join\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim import models, similarities\n",
    "\n",
    "dictionary = Dictionary.load('dewac_noun_tfidf.dict')\n",
    "corpus = MmCorpus('dewac_noun_tfidf.mm')\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-28 20:13:57,368 : INFO : loading LsiModel object from dewac_LSImodel_100\n",
      "2018-11-28 20:13:57,412 : INFO : loading id2word recursively from dewac_LSImodel_100.id2word.* with mmap=None\n",
      "2018-11-28 20:13:57,413 : INFO : setting ignored attribute projection to None\n",
      "2018-11-28 20:13:57,413 : INFO : setting ignored attribute dispatcher to None\n",
      "2018-11-28 20:13:57,413 : INFO : loaded dewac_LSImodel_100\n",
      "2018-11-28 20:13:57,414 : INFO : loading LsiModel object from dewac_LSImodel_100.projection\n",
      "2018-11-28 20:13:57,800 : INFO : loaded dewac_LSImodel_100.projection\n"
     ]
    }
   ],
   "source": [
    "lsi = models.LsiModel.load('dewac_LSImodel_100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose a user typed in the query *“Human computer interaction”*. We would like to sort our nine corpus documents in decreasing order of relevance to this query. Unlike modern search engines, here we only concentrate on a single aspect of possible similarities—on apparent semantic relatedness of their texts (words). No hyperlinks, no random-walk static ranks, just a semantic extension over the boolean keyword match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(184, 1), (15991, 1)]\n",
      "[(0, 0.029593182003438412), (1, 0.007539014057921945), (2, -0.02160713982309926), (3, -0.005549113087644178), (4, -0.0034824868502470394), (5, -0.027274555137378843), (6, -0.01935030923073703), (7, -0.031014676043065795), (8, -0.003704357303702175), (9, -0.01268476126847821), (10, -0.02895186390752488), (11, 0.001876340369223607), (12, 0.0062180141473300995), (13, -0.03633695742145685), (14, 0.017898365657640587), (15, 0.0023357964570057134), (16, -0.0358114602962959), (17, -0.013174186211293352), (18, 0.006075862561866364), (19, -0.008225892161631816), (20, -0.010348577723679761), (21, 0.04484566144346404), (22, -0.011065517935184215), (23, 0.013673016697683562), (24, 0.06806759374058592), (25, -0.039074340092499396), (26, -0.04555679800506657), (27, 0.004960719790031228), (28, -0.039189714492645626), (29, 0.0064260593211559695), (30, -0.014460057880298886), (31, 0.01307748894852384), (32, 0.002146679463034294), (33, -0.02440269856744703), (34, -0.05865720219414086), (35, 0.01018241513557625), (36, 0.0002629418293210072), (37, 0.044013526468060234), (38, 0.004447552019681899), (39, -0.034400432665963904), (40, 0.030380294259034202), (41, -0.04506859155416237), (42, -0.04584398993092716), (43, -0.010997246597269887), (44, -0.05300269185631289), (45, 0.0381926598634229), (46, 0.03673502048204722), (47, -0.009686520791437172), (48, 0.060426618493411514), (49, -0.020962953063802397), (50, -0.04286661355630179), (51, -0.005199868432897352), (52, 0.08118966345321231), (53, -0.05066165445237849), (54, 0.0219503056691582), (55, -0.004105308609999377), (56, 0.004805861068863301), (57, -0.06653258787549608), (58, 0.02762785757574615), (59, -0.0048272803051899234), (60, -0.033885977281132594), (61, -0.02851352926493358), (62, -0.007052657998198108), (63, -0.01714755792639686), (64, -0.005131979079486349), (65, 0.012388288815004388), (66, -0.030005588371311884), (67, -0.03776188572531046), (68, -0.031056680117700804), (69, 0.0001840404880646822), (70, -0.014711779893374903), (71, 0.10720658121311827), (72, 0.022018041965662764), (73, 0.039315161853520166), (74, -0.0414456014642175), (75, -0.025338517610757852), (76, -0.03173960395694312), (77, 0.03791938964744758), (78, 0.002187777825157482), (79, 0.005638745583939901), (80, 0.04085897481454036), (81, 0.007496342879093489), (82, 0.03319963891352707), (83, 0.010954046941932645), (84, 0.006081113818002314), (85, 0.008995122405582217), (86, -0.02503511303118441), (87, -0.002224247177358532), (88, 0.05569418591330391), (89, -0.003231338573248666), (90, -0.001297146219616896), (91, -0.014506775463873632), (92, -0.014431969901807628), (93, -0.009695261310351226), (94, -0.0109791379994194), (95, -0.008761119233952716), (96, 0.032198814778718624), (97, -0.016312826057109632), (98, -0.012258955574713275), (99, 0.022144553849618817)]\n"
     ]
    }
   ],
   "source": [
    "doc = \"Computer Intelligenz\"\n",
    "vec_bow = dictionary.doc2bow(doc.split())\n",
    "print(vec_bow)\n",
    "vec_lsi = lsi[vec_bow] # convert the query to LSI space\n",
    "print(vec_lsi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we will be considering [cosine](http://en.wikipedia.org/wiki/Cosine_similarity) similarity to determine the similarity of two vectors. Cosine similarity is a standard measure in Vector Space Modeling, but wherever the vectors represent probability distributions, [different similarity measures](http://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Symmetrised_divergence) may be more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing query structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare for similarity queries, we need to enter all documents which we want to compare against subsequent queries. In our case, they are the same nine documents used for training LSI, converted to 2-D LSA space. But that’s only incidental, we might also be indexing a different corpus altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-28 20:15:28,109 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "2018-11-28 20:19:04,946 : INFO : creating matrix with 1747499 documents and 100 features\n",
      "/home/andreas/bin/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "index = similarities.MatrixSimilarity(lsi[corpus]) # transform corpus to LSI space and index it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <B>Warning</B>:\n",
    "> The class `similarities.MatrixSimilarity` is only appropriate when the whole set of vectors fits into memory. For example, a corpus of one million documents would require 2GB of RAM in a 256-dimensional LSI space, when used with this class.\n",
    "> Without 2GB of free RAM, you would need to use the `similarities.Similarity` class. This class operates in fixed memory, by splitting the index across multiple files on disk, called shards. It uses `similarities.MatrixSimilarity` and `similarities.SparseMatrixSimilarity` internally, so it is still fast, although slightly more complex.\n",
    "\n",
    "Index persistency is handled via the standard save() and load() functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-28 20:24:29,814 : INFO : saving MatrixSimilarity object under dewac.index, separately None\n",
      "2018-11-28 20:24:29,815 : INFO : storing np array 'index' to dewac.index.index.npy\n",
      "2018-11-28 20:24:30,116 : INFO : saved dewac.index\n"
     ]
    }
   ],
   "source": [
    "index.save('dewac.index')\n",
    "#index = similarities.MatrixSimilarity.load('dewac_noun_tfidf.mm.index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is true for all similarity indexing classes (`similarities.Similarity`, `similarities.MatrixSimilarity` and `similarities.SparseMatrixSimilarity`). Also in the following, index can be an object of any of these. When in doubt, use `similarities.Similarity`, as it is the most scalable version, and it also supports adding more documents to the index later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain similarities of our query document against the nine indexed documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.05882028), (1, 0.01627208), (2, -0.008270286), (3, -0.024598738), (4, 0.010590587), (5, -0.03251593), (6, 0.040067364), (7, -0.018309794), (8, 0.039401855), (9, 0.053282425)]\n"
     ]
    }
   ],
   "source": [
    "sims = index[vec_lsi] # perform a similarity query against the corpus\n",
    "print(list(enumerate(sims))[:10]) # print (document_number, document_similarity) 2-tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine measure returns similarities in the range *<-1, 1>* (the greater, the more similar), so that the first document has a score of 0.99809301 etc.\n",
    "\n",
    "With some standard Python magic we sort these similarities into descending order, and obtain the final answer to the query *“Human computer interaction”*:\n",
    "\n",
    "```\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "print(sims) # print sorted (document number, similarity score) 2-tuples\n",
    "\n",
    "[(2, 0.99844527), # The EPS user interface management system\n",
    "(0, 0.99809301), # Human machine interface for lab abc computer applications\n",
    "(3, 0.9865886), # System and human system engineering testing of EPS\n",
    "(1, 0.93748635), # A survey of user opinion of computer system response time\n",
    "(4, 0.90755945), # Relation of user perceived response time to error measurement\n",
    "(8, 0.050041795), # Graph minors A survey\n",
    "(7, -0.098794639), # Graph minors IV Widths of trees and well quasi ordering\n",
    "(6, -0.1063926), # The intersection graph of paths in trees\n",
    "(5, -0.12416792)] # The generation of random binary unordered trees\n",
    "```\n",
    "\n",
    "(I added the original documents in their “string form” to the output comments, to improve clarity.)\n",
    "\n",
    "The thing to note here is that documents no. 2 (\"`The EPS user interface management system`\") and 4 (\"`Relation of user perceived response time to error measurement`\") would never be returned by a standard boolean fulltext search, because they do not share any common words with \"`Human computer interaction`\". However, after applying LSI, we can observe that both of them received quite high similarity scores (no. 2 is actually the most similar!), which corresponds better to our intuition of them sharing a “computer-human” related topic with the query. In fact, this semantic generalization is the reason why we apply transformations and do topic modelling in the first place.\n",
    "\n",
    "## Where next?\n",
    "\n",
    "Congratulations, you have finished the tutorials – now you know how gensim works :-) To delve into more details, you can browse through the [API documentation](https://radimrehurek.com/gensim/apiref.html), see the [Wikipedia experiments](https://radimrehurek.com/gensim/wiki.html) or perhaps check out [distributed computing](https://radimrehurek.com/gensim/distributed.html) in gensim.\n",
    "\n",
    "Gensim is a fairly mature package that has been used successfully by many individuals and companies, both for rapid prototyping and in production. That doesn’t mean it’s perfect though:\n",
    "\n",
    "* there are parts that could be implemented more efficiently (in C, for example), or make better use of parallelism (multiple machines cores)\n",
    "* new algorithms are published all the time; help gensim keep up by [discussing them](http://groups.google.com/group/gensim) and [contributing code](https://github.com/piskvorky/gensim/wiki/Developer-page)\n",
    "* your **feedback is most welcome** and appreciated (and it’s not just the code!): [idea contributions](https://github.com/piskvorky/gensim/wiki/Ideas-&-Features-proposals), [bug reports](https://github.com/piskvorky/gensim/issues) or just consider contributing [user stories and general questions](http://groups.google.com/group/gensim/topics).\n",
    "Gensim has no ambition to become an all-encompassing framework, across all NLP (or even Machine Learning) subfields. Its mission is to help NLP practicioners try out popular topic modelling algorithms on large datasets easily, and to facilitate prototyping of new algorithms for researchers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(518630, 0.9707641),\n",
      " (515343, 0.9681375),\n",
      " (319725, 0.9644809),\n",
      " (53222, 0.96094453),\n",
      " (1517932, 0.96056753),\n",
      " (1345555, 0.9604026),\n",
      " (686342, 0.9587432),\n",
      " (704754, 0.95739096),\n",
      " (249265, 0.95710075),\n",
      " (6164, 0.956691)]\n"
     ]
    }
   ],
   "source": [
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "from pprint import pprint\n",
    "pprint(sims[:10]) # print sorted (document number, similarity score) 2-tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(414, 0.1365903136730849),\n",
       " (765, 0.17590438271376627),\n",
       " (780, 0.05713405394829304),\n",
       " (4423, 0.23041858142911847),\n",
       " (20803, 0.3372746962885819),\n",
       " (22589, 0.43506244688802703),\n",
       " (36560, 0.29564119039759584),\n",
       " (42951, 0.38746276962682985),\n",
       " (66615, 0.41586608786909596),\n",
       " (77043, 0.42489344990185823)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[518630]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('dewac_noun_texts.json', 'r') as fp:\n",
    "    texts = json.load(fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Frage',\n",
       " 'Schwangerschaft',\n",
       " 'Jugendalter',\n",
       " 'Thema',\n",
       " 'Lösung',\n",
       " 'Konflikt',\n",
       " 'Einrichtung',\n",
       " 'Unterstützung',\n",
       " 'Beratung',\n",
       " 'Gymnasium',\n",
       " 'Mitschüler',\n",
       " 'Rahmen',\n",
       " 'Projekt',\n",
       " 'Thema',\n",
       " 'Jugendliche',\n",
       " 'Schwangerschaftskonflikt\\x93',\n",
       " 'Schwerpunkt',\n",
       " 'Schwerpunkt',\n",
       " 'Recherche',\n",
       " 'Thema',\n",
       " 'Einrichtung',\n",
       " 'Jugendliche',\n",
       " 'Entscheidung',\n",
       " 'Situation',\n",
       " 'Ende',\n",
       " 'Entscheidung',\n",
       " 'Gruß',\n",
       " 'Fenja',\n",
       " 'Buddenberg',\n",
       " 'Anmerkung',\n",
       " 'Präsentation',\n",
       " 'Ausarbeitung',\n",
       " 'Projekt',\n",
       " 'Überarbeitung',\n",
       " 'Ergänzung',\n",
       " 'Seite',\n",
       " 'Material',\n",
       " 'Recherche',\n",
       " 'Thema',\n",
       " 'Foto',\n",
       " 'Sternipark',\n",
       " 'Weile']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[515343]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
